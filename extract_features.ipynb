{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from tqdm import tqdm\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    import cv2\n",
    "    import json\n",
    "    import pywt\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import shap\n",
    "    from lib.utils import inverti_maschera_binaria\n",
    "    from PIL import Image, ImageOps\n",
    "except Exception as e:\n",
    "    print(f\"Some module are missing: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data: np.ndarray, bins: int = 256) -> float:\n",
    "    data_flat = data.flatten()\n",
    "    histogram, _ = np.histogram(data_flat, bins=bins, range=(0, bins), density=True)\n",
    "    entropy = -np.sum(histogram * np.log2(histogram + 1e-10))\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def clalc_shift_spect(img):\n",
    "    f = np.fft.fft2(img)\n",
    "\n",
    "    coeffs = pywt.wavedec2(img, \"haar\", level=2)\n",
    "    return f, coeffs\n",
    "\n",
    "\n",
    "def extract_frequency_features(\n",
    "    image: Path | np.ndarray, wavelet: str = \"db4\", bins: int = 256, invert_mask=False\n",
    ") -> dict:\n",
    "    image = image.resolve()\n",
    "    if isinstance(image, Path):\n",
    "        img = cv2.imread(str(image), cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        img = image.copy()\n",
    "        if len(img.shape) == 3:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "    if invert_mask:\n",
    "        img = cv2.bitwise_not(img)\n",
    "\n",
    "    # f = np.fft.fft2(img)\n",
    "    f, coeffs = clalc_shift_spect(img)\n",
    "    fshift = np.fft.fftshift(f)\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1e-10)\n",
    "\n",
    "    mean_freq = np.mean(magnitude_spectrum)\n",
    "    std_freq = np.std(magnitude_spectrum)\n",
    "    max_freq = np.max(magnitude_spectrum)\n",
    "    min_freq = np.min(magnitude_spectrum)\n",
    "    median_freq = np.median(magnitude_spectrum)\n",
    "    energy = np.sum(np.abs(fshift) ** 2)\n",
    "\n",
    "    rows, cols = magnitude_spectrum.shape\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "\n",
    "    histogram, _ = np.histogram(\n",
    "        magnitude_spectrum, bins=bins, range=(0, bins), density=True\n",
    "    )\n",
    "    entropy = -np.sum(histogram * np.log2(histogram + 1e-10))\n",
    "\n",
    "    low_freq_energy = np.sum(magnitude_spectrum[:crow, :ccol])\n",
    "    high_freq_energy = np.sum(magnitude_spectrum[crow:, ccol:])\n",
    "    frequency_contrast = high_freq_energy - low_freq_energy\n",
    "\n",
    "    # coeffs = pywt.wavedec2(img, wavelet, level=2)\n",
    "    cA2, (cH2, cV2, cD2), (cH1, cV1, cD1) = coeffs\n",
    "\n",
    "    wavelet_features = {\n",
    "        \"wavelet_energy_A2\": np.sum(np.square(cA2)),\n",
    "        \"wavelet_energy_H2\": np.sum(np.square(cH2)),\n",
    "        \"wavelet_energy_V2\": np.sum(np.square(cV2)),\n",
    "        \"wavelet_energy_D2\": np.sum(np.square(cD2)),\n",
    "        \"wavelet_std_A2\": np.std(cA2),\n",
    "        \"wavelet_std_H2\": np.std(cH2),\n",
    "        \"wavelet_std_V2\": np.std(cV2),\n",
    "        \"wavelet_std_D2\": np.std(cD2),\n",
    "        \"wavelet_energy_H1\": np.sum(np.square(cH1)),\n",
    "        \"wavelet_energy_V1\": np.sum(np.square(cV1)),\n",
    "        \"wavelet_energy_D1\": np.sum(np.square(cD1)),\n",
    "        \"wavelet_std_H1\": np.std(cH1),\n",
    "        \"wavelet_std_V1\": np.std(cV1),\n",
    "        \"wavelet_std_D1\": np.std(cD1),\n",
    "        \"wavelet_entropy_A2\": calculate_entropy(cA2, bins),\n",
    "        \"wavelet_entropy_H2\": calculate_entropy(cH2, bins),\n",
    "        \"wavelet_entropy_V2\": calculate_entropy(cV2, bins),\n",
    "        \"wavelet_entropy_D2\": calculate_entropy(cD2, bins),\n",
    "        \"wavelet_entropy_H1\": calculate_entropy(cH1, bins),\n",
    "        \"wavelet_entropy_V1\": calculate_entropy(cV1, bins),\n",
    "        \"wavelet_entropy_D1\": calculate_entropy(cD1, bins),\n",
    "    }\n",
    "\n",
    "    frequency_features = {\n",
    "        \"mean_frequency\": mean_freq,\n",
    "        \"std_frequency\": std_freq,\n",
    "        \"max_frequency\": max_freq,\n",
    "        \"min_frequency\": min_freq,\n",
    "        \"median_frequency\": median_freq,\n",
    "        \"energy\": energy,\n",
    "        \"entropy\": entropy,\n",
    "        \"low_frequency_energy\": low_freq_energy,\n",
    "        \"high_frequency_energy\": high_freq_energy,\n",
    "        \"frequency_contrast\": frequency_contrast,\n",
    "    }\n",
    "\n",
    "    frequency_features.update(wavelet_features)\n",
    "\n",
    "    return frequency_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:32<00:00, 151.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#images_path=Path(\"/home/tommaso/git_workspace/VAE_DefectedGraphene/results/generated_test\")\n",
    "images_path=Path(\"/home/tommaso/git_workspace/VAE_DefectedGraphene/results/26_10/generated_dataset\")\n",
    "frequency_dict = {}\n",
    "\n",
    "images = [f for f in images_path.iterdir() if f.suffix.lower() ==\".png\"]\n",
    "for image in tqdm(images):\n",
    "    dict_img = extract_frequency_features(image, invert_mask=True)\n",
    "    if int(np.loadtxt(image.with_suffix(\".txt\"))) >= 512:\n",
    "        print(\"Warning!\")\n",
    "        continue\n",
    "    else:\n",
    "        dict_img[\"n_atoms\"] = int(np.loadtxt(image.with_suffix(\".txt\")))\n",
    "        dict_img[\"file_name\"] = image.stem\n",
    "        frequency_dict[f\"{image.stem}\"] = dict_img\n",
    "\n",
    "frequency_df = pd.DataFrame.from_dict(frequency_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Supponiamo che tu abbia un DataFrame chiamato df con le tue features\n",
    "# correlation_matrix = frequency_df.corr()\n",
    "\n",
    "# # Visualizza la matrice di correlazione come una heatmap\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_image(image, size=240):\n",
    "    h = image.shape[0]\n",
    "    w = image.shape[1]\n",
    "\n",
    "    top = round((size - h) / 2)\n",
    "    bottom = size - (h + top)\n",
    "\n",
    "    left = round((size - w) / 2)\n",
    "    right = size - (w + left)\n",
    "\n",
    "    padded_img = cv2.copyMakeBorder(\n",
    "        image, top, bottom, left, right, cv2.BORDER_CONSTANT, None, 255\n",
    "    )\n",
    "\n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conta_atomi_da_xyz(spath: Path):\n",
    "        \"\"\"Read xyz files and return lists of x,y,z coordinates and atoms\"\"\"\n",
    "\n",
    "        atoms = []\n",
    "\n",
    "        with open(str(spath), \"r\") as f:\n",
    "            for line in f:\n",
    "                l = line.split()\n",
    "                if len(l) == 4 or len(l) == 5:\n",
    "                    atoms.append(str(l[0]))\n",
    "\n",
    "        return len(atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_path=Path(\"/home/tommaso/git_workspace/VAE_DefectedGraphene/data/images_240\")\n",
    "# images = [f for f in images_path.iterdir() if f.suffix.lower() ==\".png\"]\n",
    "# for image in images:\n",
    "#     img=inverti_maschera_binaria(str(image))\n",
    "#     img.save(Path(f\"/home/tommaso/git_workspace/VAE_DefectedGraphene/analysis/reverted_dataset_image/{image.name}\"))\n",
    "    \n",
    "# images_path=Path(\"/home/tommaso/git_workspace/VAE_DefectedGraphene/analysis/reverted_dataset_image\")\n",
    "# images = [f for f in images_path.iterdir() if f.suffix.lower() ==\".png\"] \n",
    "# for image in images:\n",
    "#     img = cv2.imread(str(image),0)\n",
    "#     img = padding_image(img,size=240)\n",
    "#     cv2.imwrite(str(Path(f\"/home/tommaso/git_workspace/VAE_DefectedGraphene/analysis/padded/{image.name}\")),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8750/8750 [01:02<00:00, 139.38it/s]\n"
     ]
    }
   ],
   "source": [
    "images_path=Path(\"/home/tommaso/git_workspace/VAE_DefectedGraphene/analysis/padded\")\n",
    "frequency_dict = {}\n",
    "\n",
    "images = [f for f in images_path.iterdir() if f.suffix.lower() ==\".png\"]\n",
    "for image in tqdm(images):\n",
    "    dict_img = extract_frequency_features(image, invert_mask=True)\n",
    "    dict_img[\"n_atoms\"] = conta_atomi_da_xyz(Path(f\"/home/tommaso/git_workspace/VAE_DefectedGraphene/data/xyz_files/{image.stem}.xyz\"))\n",
    "    dict_img[\"file_name\"] = image.stem\n",
    "    frequency_dict[f\"{image.stem}\"] = dict_img\n",
    "\n",
    "original_frequency_df = pd.DataFrame.from_dict(frequency_dict, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_df.to_csv(f\"/home/tommaso/git_workspace/VAE_DefectedGraphene/analysis/generated_df.csv\", index=False)\n",
    "original_frequency_df.to_csv(f\"/home/tommaso/git_workspace/VAE_DefectedGraphene/analysis/original_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
